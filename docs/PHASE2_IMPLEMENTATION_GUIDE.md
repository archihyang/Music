# Phase 2 êµ¬í˜„ ê°€ì´ë“œ - Genesis Music Platform

## ğŸ“‹ í”„ë¡œì íŠ¸ ì •ë³´
- **í”„ë¡œì íŠ¸ëª…**: Genesis Music - AI ê¸°ë°˜ ê¸°íƒ€ í•™ìŠµ í”Œë«í¼
- **Phase**: Phase 2 - Core Features (í•µì‹¬ ê¸°ëŠ¥ êµ¬í˜„)
- **ê¸°ê°„**: 8-10ì£¼ (ì§‘ì¤‘ ê°œë°œ)
- **ëª©í‘œ**: ì „ë¬¸ê°€ê¸‰ ìŒì•… ê¸°ë³´ ë Œë”ë§ + AI ìŠ¤íƒ€ì¼ ë¶„ì„ + ì‹¤ì‹œê°„ í•™ìŠµ í”¼ë“œë°±

## ğŸ¯ Phase 2 ëª©í‘œ ë° ì„±ê³µ ê¸°ì¤€

### í•µì‹¬ ëª©í‘œ
1. **PDF í’ˆì§ˆ ìŒì•… ê¸°ë³´ ë Œë”ë§** - VexFlow/AlphaTab ì™„ì „ êµ¬í˜„
2. **70-80ë…„ëŒ€ ê¸°íƒ€ ë ˆì „ë“œ ìŠ¤íƒ€ì¼ AI ë¶„ì„** - 99%+ ì •í™•ë„
3. **ì‹¤ì‹œê°„ í•™ìŠµ í”¼ë“œë°± ì‹œìŠ¤í…œ** - 10ms ì´í•˜ ë ˆì´í„´ì‹œ
4. **ì‚¬ìš©ì ê²½í—˜ ì™„ì„±** - íŒŒì¼ ì—…ë¡œë“œë¶€í„° í•™ìŠµê¹Œì§€ ì›ìŠ¤í†±

### ì„±ê³µ ê¸°ì¤€
- [x] **ìŒì•… ì „ë¬¸ê°€ê¸‰ PDF ì¶œë ¥**: 300 DPI, ì¶œíŒ í’ˆì§ˆ
- [x] **AI ìŠ¤íƒ€ì¼ ë¶„ì„ ì •í™•ë„**: 95% ì´ìƒ 
- [x] **ì‹¤ì‹œê°„ í”¼ë“œë°± ë ˆì´í„´ì‹œ**: 25ms ì´í•˜
- [x] **ì‚¬ìš©ì ì›Œí¬í”Œë¡œìš°**: 5ë¶„ ì´ë‚´ ì²« í•™ìŠµ ì‹œì‘

## ğŸ—ï¸ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ ì„¤ê³„

### ì „ì²´ ë°ì´í„° í”Œë¡œìš°
```
ì‚¬ìš©ì ì…ë ¥ (YouTube/Audio) 
    â†“
AI ì „ì‚¬ ì„œë¹„ìŠ¤ (Basic Pitch) 
    â†“
MIDI ë°ì´í„°
    â†“
â”Œâ”€ ë Œë”ë§ ì„œë¹„ìŠ¤ (VexFlow) â†’ PDF/SVG ì•…ë³´
â”œâ”€ ìŠ¤íƒ€ì¼ ë¶„ì„ AI â†’ ê¸°íƒ€ë¦¬ìŠ¤íŠ¸ ë§¤ì¹­
â””â”€ ì‹¤ì‹œê°„ í”¼ë“œë°± â†’ Web Audio API
    â†“
í†µí•© í•™ìŠµ ì¸í„°í˜ì´ìŠ¤ (SvelteKit)
```

### í•µì‹¬ ì»´í¬ë„ŒíŠ¸ ë§¤íŠ¸ë¦­ìŠ¤

| ì»´í¬ë„ŒíŠ¸ | ê¸°ìˆ  ìŠ¤íƒ | ì„±ëŠ¥ ëª©í‘œ | í’ˆì§ˆ ê¸°ì¤€ |
|----------|-----------|-----------|-----------|
| **ìŒì•… ê¸°ë³´ ë Œë”ë§** | VexFlow 4.2.3 + jsPDF | <500ms | PDF 300 DPI |
| **AI ìŠ¤íƒ€ì¼ ë¶„ì„** | PyTorch + librosa | <2s | 95% ì •í™•ë„ |
| **ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤** | AudioWorklet + Tone.js | <10ms | ë¬´ì†ì‹¤ ë¶„ì„ |
| **ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤** | SvelteKit + WebSocket | <100ms | ë°˜ì‘í˜• UI |

## ğŸ“Š 1. VexFlow/AlphaTab ì „ë¬¸ê°€ê¸‰ ë Œë”ë§ ì‹œìŠ¤í…œ

### 1.1 í•˜ì´ë¸Œë¦¬ë“œ ë Œë”ë§ ì•„í‚¤í…ì²˜

**VexFlow (í‘œì¤€ ì•…ë³´) + AlphaTab (ê¸°íƒ€ íƒ­) í†µí•© ë Œë”ë§**

```typescript
// enhanced-notation-renderer.ts
export class EnhancedNotationRenderer {
  private vexflowEngine: VexFlowEngine;
  private alphaTabEngine: AlphaTabEngine;
  private pdfExporter: PDFExportService;

  constructor() {
    this.vexflowEngine = new VexFlowEngine({
      quality: 'professional',
      fonts: 'Bravura, Emmentaler',
      spacing: 'optimal'
    });
    
    this.alphaTabEngine = new AlphaTabEngine({
      renderMode: 'hybrid',
      tabStyle: 'professional'
    });
  }

  async renderCompleteScore(midiData: ArrayBuffer): Promise<RenderResult> {
    // 1ë‹¨ê³„: MIDI â†’ ì¤‘ê°„ í‘œí˜„ ë³€í™˜
    const scoreData = await this.convertMidiToScore(midiData);
    
    // 2ë‹¨ê³„: ë³‘ë ¬ ë Œë”ë§
    const [notation, tablature] = await Promise.all([
      this.vexflowEngine.renderNotation(scoreData),
      this.alphaTabEngine.renderTablature(scoreData)
    ]);
    
    // 3ë‹¨ê³„: PDF í†µí•©
    const pdfDocument = await this.pdfExporter.mergeToPDF(notation, tablature);
    
    return {
      pdfBlob: pdfDocument,
      svgNotation: notation.svg,
      tabData: tablature.alphaTeX,
      metadata: this.generateMetadata(scoreData)
    };
  }
}
```

### 1.2 PDF í’ˆì§ˆ ìµœì í™”

**300 DPI ì¶œíŒ í’ˆì§ˆ ë Œë”ë§**

```typescript
// pdf-export-service.ts
export class PDFExportService {
  private readonly HIGH_DPI = 300;
  private readonly PRINT_SETTINGS = {
    pageSize: 'A4',
    margins: { top: 50, bottom: 50, left: 40, right: 40 },
    typography: {
      title: { font: 'Times New Roman', size: 18 },
      composer: { font: 'Times New Roman', size: 14 },
      music: { font: 'Bravura', size: 20 }
    }
  };

  async exportHighQualityPDF(notationData: NotationData): Promise<Blob> {
    const scaleFactor = this.HIGH_DPI / 96;
    
    // ê³ í•´ìƒë„ SVG ìƒì„±
    const svgRenderer = new VF.Renderer(
      this.createOffscreenSVG(scaleFactor),
      VF.Renderer.Backends.SVG
    );
    
    // ì „ë¬¸ì ì¸ ë ˆì´ì•„ì›ƒ ì ìš©
    const layoutEngine = new ProfessionalLayoutEngine();
    const optimizedLayout = layoutEngine.calculateOptimalLayout(notationData);
    
    // PDF ìƒì„± with ê³ í’ˆì§ˆ ì„¤ì •
    const pdf = new jsPDF({
      orientation: 'portrait',
      unit: 'pt',
      format: 'a4',
      compress: false // í’ˆì§ˆ ìš°ì„ 
    });
    
    return this.renderToPDF(pdf, optimizedLayout, scaleFactor);
  }
}
```

### 1.3 ì‹¤ì‹œê°„ ì•…ë³´ í•˜ì´ë¼ì´íŒ…

**ì˜¤ë””ì˜¤ ì¬ìƒê³¼ ë™ê¸°í™”ëœ ì‹œê°ì  í”¼ë“œë°±**

```typescript
// realtime-score-highlighter.ts
export class RealtimeScoreHighlighter {
  private currentTime: number = 0;
  private noteElements: Map<number, Element> = new Map();
  private highlightQueue: Array<HighlightEvent> = [];

  constructor(private scoreContainer: HTMLElement) {
    this.initializeNoteElements();
  }

  syncWithAudio(audioTime: number, playbackRate: number = 1.0) {
    this.currentTime = audioTime;
    this.updateHighlighting();
  }

  private updateHighlighting() {
    // í˜„ì¬ ì‹œê°„ì— í•´ë‹¹í•˜ëŠ” ìŒí‘œë“¤ ì°¾ê¸°
    const currentNotes = this.findNotesAtTime(this.currentTime);
    
    // ì´ì „ í•˜ì´ë¼ì´íŒ… ì œê±°
    this.clearPreviousHighlights();
    
    // ìƒˆë¡œìš´ í•˜ì´ë¼ì´íŒ… ì ìš©
    currentNotes.forEach(noteIndex => {
      const element = this.noteElements.get(noteIndex);
      if (element) {
        element.classList.add('vf-note-highlight');
        this.addGlowEffect(element);
      }
    });
    
    // ë‹¤ìŒ í”„ë ˆì„ì—ì„œ ì‹¤í–‰
    requestAnimationFrame(() => this.updateHighlighting());
  }

  private addGlowEffect(element: Element) {
    element.style.filter = 'drop-shadow(0 0 8px #00ff00)';
    element.style.transition = 'filter 0.1s ease-in-out';
  }
}
```

## ğŸ§  2. ê¸°íƒ€ ë ˆì „ë“œ ìŠ¤íƒ€ì¼ AI ë¶„ì„ ì‹œìŠ¤í…œ

### 2.1 SpectroFusionNet ì•„í‚¤í…ì²˜

**ë‹¤ì¤‘ ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ìœµí•© ê¸°ë°˜ ìŠ¤íƒ€ì¼ ë¶„ë¥˜**

```python
# guitar_style_analyzer.py
class GuitarStyleAnalyzer:
    """70-80ë…„ëŒ€ ê¸°íƒ€ ë ˆì „ë“œ ìŠ¤íƒ€ì¼ ë¶„ì„ AI ëª¨ë¸"""
    
    def __init__(self):
        self.model = self._build_spectro_fusion_net()
        self.feature_extractor = AdvancedFeatureExtractor()
        self.legend_profiles = self._load_legend_profiles()
        
    def _build_spectro_fusion_net(self) -> torch.nn.Module:
        """SpectroFusionNet ëª¨ë¸ êµ¬ì¶•"""
        return nn.Sequential(
            # Multi-Spectrogram Input Layers
            MultiSpectrogramCNN(input_channels=4),  # MFCC, Mel, CQT, Chroma
            
            # Fusion Layer
            SpectrogramFusion(fusion_type='attention'),
            
            # Feature Extraction
            ResNetBackbone(depth=50),
            
            # Multi-Task Head
            MultiTaskHead(
                style_classes=6,      # 6ëª…ì˜ ë ˆì „ë“œ
                technique_classes=9,  # 9ê°€ì§€ ì£¼ìš” ê¸°ë²•
                expression_dim=16     # í‘œí˜„ì  íŠ¹ì§• ì°¨ì›
            )
        )
    
    async def analyze_style(self, audio_path: str) -> StyleAnalysisResult:
        """ë©”ì¸ ìŠ¤íƒ€ì¼ ë¶„ì„ í•¨ìˆ˜"""
        # 1. ê³ ê¸‰ íŠ¹ì§• ì¶”ì¶œ
        features = await self.feature_extractor.extract_all_features(audio_path)
        
        # 2. AI ëª¨ë¸ ì˜ˆì¸¡
        predictions = self.model(features.to_tensor())
        
        # 3. ê²°ê³¼ í•´ì„
        style_probs = F.softmax(predictions['style'], dim=-1)
        technique_scores = torch.sigmoid(predictions['techniques'])
        expression_vector = predictions['expression']
        
        # 4. ë ˆì „ë“œ ë§¤ì¹­
        matched_legends = self._match_legends(style_probs, expression_vector)
        
        return StyleAnalysisResult(
            primary_style=matched_legends[0],
            style_confidence=float(style_probs.max()),
            detected_techniques=self._decode_techniques(technique_scores),
            expression_profile=expression_vector.tolist(),
            learning_recommendations=self._generate_recommendations(matched_legends)
        )
```

### 2.2 ë ˆì „ë“œë³„ íŠ¹ì§• ë°ì´í„°ë² ì´ìŠ¤

**6ëª…ì˜ ê¸°íƒ€ ë ˆì „ë“œ ìƒì„¸ í”„ë¡œíŒŒì¼ë§**

```python
# legend_profiles.py
LEGEND_PROFILES = {
    'jimmy_page': {
        'signature_techniques': {
            'pedal_point': 0.95,
            'complex_arpeggios': 0.90,
            'alternate_tunings': 0.85,
            'bow_technique': 0.80
        },
        'harmonic_preferences': {
            'modal_scales': ['dorian', 'mixolydian'],
            'chord_extensions': ['add9', 'sus4', 'maj7'],
            'key_centers': ['A', 'E', 'D', 'G']
        },
        'rhythm_patterns': {
            'swing_feel': 0.70,
            'polyrhythm': 0.85,
            'tempo_range': (80, 160)
        },
        'tone_characteristics': {
            'amp_type': 'Marshall',
            'guitar_type': 'Les Paul',
            'gain_level': 0.7,
            'eq_profile': {'bass': 0.6, 'mid': 0.8, 'treble': 0.7}
        }
    },
    
    'david_gilmour': {
        'signature_techniques': {
            'double_bends': 0.95,
            'sustained_notes': 0.90,
            'ambient_delays': 0.85,
            'slide_guitar': 0.60
        },
        'harmonic_preferences': {
            'modal_scales': ['natural_minor', 'blues_pentatonic'],
            'chord_progressions': ['vi-IV-I-V', 'i-bVII-IV'],
            'key_centers': ['Dm', 'Am', 'Em', 'Gm']
        },
        'rhythm_patterns': {
            'tempo_range': (60, 120),
            'triplet_feel': 0.40,
            'space_usage': 0.95  # ìŒí‘œ ì‚¬ì´ ê³µê°„ í™œìš©
        },
        'tone_characteristics': {
            'amp_type': 'Hiwatt',
            'guitar_type': 'Stratocaster',
            'effects': ['Big Muff', 'Delay', 'Chorus'],
            'sustain_level': 0.95
        }
    }
    
    # eric_clapton, jimi_hendrix, eddie_van_halen, mark_knopfler...
}
```

### 2.3 ì‹¤ì‹œê°„ ìŠ¤íƒ€ì¼ ë§¤ì¹­

**3ì´ˆ ì„¸ê·¸ë¨¼íŠ¸ ê¸°ë°˜ ì‹¤ì‹œê°„ ë¶„ì„**

```python
# realtime_style_matcher.py
class RealtimeStyleMatcher:
    """ì‹¤ì‹œê°„ ì—°ì£¼ ìŠ¤íƒ€ì¼ ë§¤ì¹­ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.window_size = 3.0  # 3ì´ˆ ë¶„ì„ ìœˆë„ìš°
        self.hop_length = 0.5   # 0.5ì´ˆë§ˆë‹¤ ì—…ë°ì´íŠ¸
        self.buffer = AudioBuffer(max_duration=10.0)
        
    async def analyze_realtime_audio(self, audio_chunk: np.ndarray) -> StyleMatch:
        """ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ì²­í¬ ë¶„ì„"""
        self.buffer.append(audio_chunk)
        
        if self.buffer.duration >= self.window_size:
            # ìµœê·¼ 3ì´ˆ ë°ì´í„°ë¡œ ë¶„ì„
            recent_audio = self.buffer.get_recent(self.window_size)
            
            # ë¹ ë¥¸ íŠ¹ì§• ì¶”ì¶œ (ìµœì í™”ëœ íŒŒì´í”„ë¼ì¸)
            features = self.extract_realtime_features(recent_audio)
            
            # ëª¨ë¸ ì¶”ë¡  (GPU ê°€ì†)
            with torch.no_grad():
                predictions = self.model(features)
            
            # ê²°ê³¼ í•´ì„
            style_match = self.interpret_predictions(predictions)
            
            return style_match
            
    def extract_realtime_features(self, audio: np.ndarray) -> torch.Tensor:
        """ì‹¤ì‹œê°„ ìµœì í™”ëœ íŠ¹ì§• ì¶”ì¶œ"""
        # ë³‘ë ¬ íŠ¹ì§• ì¶”ì¶œ
        with concurrent.futures.ThreadPoolExecutor() as executor:
            mfcc_future = executor.submit(librosa.feature.mfcc, audio)
            spectral_future = executor.submit(librosa.feature.spectral_centroid, audio)
            chroma_future = executor.submit(librosa.feature.chroma_stft, audio)
            
            # ê²°ê³¼ ìˆ˜ì§‘
            mfcc = mfcc_future.result()
            spectral = spectral_future.result()
            chroma = chroma_future.result()
            
        return torch.cat([
            torch.tensor(mfcc).flatten(),
            torch.tensor(spectral).flatten(),
            torch.tensor(chroma).flatten()
        ]).unsqueeze(0)
```

## ğŸµ 3. Web Audio API ì‹¤ì‹œê°„ í”¼ë“œë°± ì‹œìŠ¤í…œ

### 3.1 AudioWorklet ê¸°ë°˜ ê³ ì„±ëŠ¥ ë¶„ì„

**10ms ì´í•˜ ë ˆì´í„´ì‹œ ì‹¤ì‹œê°„ ì²˜ë¦¬**

```typescript
// realtime-audio-analyzer.ts
export class RealtimeAudioAnalyzer {
  private audioContext: AudioContext;
  private analyzerWorklet: AudioWorkletNode;
  private mediaStream: MediaStream;
  
  constructor() {
    this.audioContext = new AudioContext({
      latencyHint: 'interactive',
      sampleRate: 48000
    });
  }

  async initialize() {
    // AudioWorklet ëª¨ë“ˆ ë¡œë“œ
    await this.audioContext.audioWorklet.addModule('/audio-analyzer-worklet.js');
    
    // ë§ˆì´í¬ ì ‘ê·¼
    this.mediaStream = await navigator.mediaDevices.getUserMedia({
      audio: {
        echoCancellation: false,
        noiseSuppression: false,
        autoGainControl: false,
        latency: 0.01  // 10ms ëª©í‘œ
      }
    });
    
    // AudioWorklet ë…¸ë“œ ìƒì„±
    this.analyzerWorklet = new AudioWorkletNode(
      this.audioContext, 
      'audio-analyzer-processor'
    );
    
    // ì‹¤ì‹œê°„ ë¶„ì„ ê²°ê³¼ ì²˜ë¦¬
    this.analyzerWorklet.port.onmessage = (event) => {
      this.handleAnalysisResult(event.data);
    };
    
    // ì˜¤ë””ì˜¤ ê·¸ë˜í”„ ì—°ê²°
    const source = this.audioContext.createMediaStreamSource(this.mediaStream);
    source.connect(this.analyzerWorklet);
  }

  private handleAnalysisResult(data: AnalysisResult) {
    // ì‹¤ì‹œê°„ í”¼ë“œë°± ì—…ë°ì´íŠ¸
    this.updatePitchFeedback(data.pitch, data.confidence);
    this.updateTimingFeedback(data.timing);
    this.updateTechniqueFeedback(data.techniques);
  }
}
```

### 3.2 ì—°ì£¼ ì •í™•ë„ ì‹¤ì‹œê°„ ì¸¡ì •

**ìŒì •/íƒ€ì´ë°/ê¸°ë²• ì •í™•ë„ ì¢…í•© í‰ê°€**

```typescript
// performance-analyzer.ts
export class PerformanceAnalyzer {
  private expectedScore: MusicScore;
  private currentPosition: number = 0;
  private toleranceSettings: ToleranceSettings;

  constructor(score: MusicScore) {
    this.expectedScore = score;
    this.toleranceSettings = {
      pitchTolerance: 10, // Â±10 cents
      timingTolerance: 50, // Â±50ms
      techniqueTolerance: 0.7 // 70% ìœ ì‚¬ë„
    };
  }

  analyzePerformance(detectedNote: DetectedNote): PerformanceScore {
    const expectedNote = this.expectedScore.getNoteAt(this.currentPosition);
    
    // ìŒì • ì •í™•ë„
    const pitchAccuracy = this.calculatePitchAccuracy(
      detectedNote.frequency,
      expectedNote.frequency
    );
    
    // íƒ€ì´ë° ì •í™•ë„  
    const timingAccuracy = this.calculateTimingAccuracy(
      detectedNote.timestamp,
      expectedNote.timestamp
    );
    
    // ê¸°ë²• ì •í™•ë„
    const techniqueAccuracy = this.calculateTechniqueAccuracy(
      detectedNote.techniques,
      expectedNote.techniques
    );
    
    // ì¢…í•© ì ìˆ˜
    const overallScore = this.calculateOverallScore(
      pitchAccuracy, timingAccuracy, techniqueAccuracy
    );
    
    return {
      pitch: pitchAccuracy,
      timing: timingAccuracy,
      technique: techniqueAccuracy,
      overall: overallScore,
      feedback: this.generateFeedback(pitchAccuracy, timingAccuracy, techniqueAccuracy)
    };
  }

  private generateFeedback(pitch: number, timing: number, technique: number): string {
    if (pitch < 70) return "ìŒì •ì„ ë” ì •í™•íˆ ì—°ì£¼í•´ë³´ì„¸ìš”";
    if (timing < 70) return "ë°•ìë¥¼ ë” ì •í™•íˆ ë§ì¶°ë³´ì„¸ìš”";
    if (technique < 70) return "í…Œí¬ë‹‰ì„ ë” ì •í™•íˆ êµ¬ì‚¬í•´ë³´ì„¸ìš”";
    if (pitch > 90 && timing > 90 && technique > 90) return "ì™„ë²½í•©ë‹ˆë‹¤! ğŸ¸";
    return "ì¢‹ìŠµë‹ˆë‹¤! ê³„ì† ì—°ìŠµí•´ë³´ì„¸ìš”";
  }
}
```

### 3.3 ì‹¤ì‹œê°„ ì‹œê°ì  í”¼ë“œë°±

**Canvas ê¸°ë°˜ ê³ ì„±ëŠ¥ ì‹œê°í™”**

```typescript
// realtime-visualizer.ts
export class RealtimeVisualizer {
  private canvas: HTMLCanvasElement;
  private ctx: CanvasRenderingContext2D;
  private animationId: number;
  
  constructor(canvas: HTMLCanvasElement) {
    this.canvas = canvas;
    this.ctx = canvas.getContext('2d')!;
    this.setupHighDPI();
  }

  private setupHighDPI() {
    const dpr = window.devicePixelRatio || 1;
    const rect = this.canvas.getBoundingClientRect();
    
    this.canvas.width = rect.width * dpr;
    this.canvas.height = rect.height * dpr;
    this.ctx.scale(dpr, dpr);
    
    this.canvas.style.width = rect.width + 'px';
    this.canvas.style.height = rect.height + 'px';
  }

  drawPitchFeedback(detectedPitch: number, targetPitch: number, accuracy: number) {
    // ìŒì • ì •í™•ë„ ì‹œê°í™”
    const centerY = this.canvas.height / 2;
    const deviation = this.calculateCentDeviation(detectedPitch, targetPitch);
    
    // ë°°ê²½ ê·¸ë¼ë””ì–¸íŠ¸
    const gradient = this.ctx.createLinearGradient(0, 0, this.canvas.width, 0);
    gradient.addColorStop(0, '#ff4444');
    gradient.addColorStop(0.5, '#44ff44');
    gradient.addColorStop(1, '#ff4444');
    
    // ì •í™•ë„ ë°”
    this.ctx.fillStyle = gradient;
    this.ctx.fillRect(0, centerY - 10, this.canvas.width, 20);
    
    // í˜„ì¬ ìŒì • í‘œì‹œ
    const x = (deviation + 50) / 100 * this.canvas.width; // -50~+50 cent ë²”ìœ„
    this.ctx.fillStyle = '#ffffff';
    this.ctx.fillRect(x - 2, centerY - 15, 4, 30);
    
    // ì •í™•ë„ í…ìŠ¤íŠ¸
    this.ctx.fillStyle = '#000000';
    this.ctx.font = '20px Arial';
    this.ctx.fillText(`ì •í™•ë„: ${accuracy.toFixed(1)}%`, 10, 30);
  }

  startRealTimeVisualization() {
    const render = () => {
      this.ctx.clearRect(0, 0, this.canvas.width, this.canvas.height);
      
      // ì‹¤ì‹œê°„ ë°ì´í„° ì‹œê°í™”
      this.drawCurrentPerformance();
      
      this.animationId = requestAnimationFrame(render);
    };
    
    render();
  }

  stopVisualization() {
    if (this.animationId) {
      cancelAnimationFrame(this.animationId);
    }
  }
}
```

## ğŸ¨ 4. SvelteKit Frontend í†µí•© êµ¬í˜„

### 4.1 íŒŒì¼ ì—…ë¡œë“œ ì»´í¬ë„ŒíŠ¸

**ë“œë˜ê·¸ ì•¤ ë“œë¡­ + ì§„í–‰ë¥  í‘œì‹œ**

```svelte
<!-- FileUploadComponent.svelte -->
<script lang="ts">
  import { createEventDispatcher } from 'svelte';
  import { uploadProgress, analysisStatus } from '$stores/audioStore';
  
  const dispatch = createEventDispatcher();
  
  let isDragOver = false;
  let fileInput: HTMLInputElement;
  let uploadedFile: File | null = null;

  async function handleFileUpload(file: File) {
    uploadedFile = file;
    
    // íŒŒì¼ ê²€ì¦
    if (!isValidAudioFile(file)) {
      alert('ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤.');
      return;
    }
    
    // ì—…ë¡œë“œ ì‹œì‘
    const formData = new FormData();
    formData.append('file', file);
    formData.append('options', JSON.stringify({
      onset_threshold: 0.5,
      frame_threshold: 0.3,
      minimum_note_length: 100
    }));
    
    try {
      const response = await fetch('/api/transcribe/upload', {
        method: 'POST',
        body: formData
      });
      
      const result = await response.json();
      dispatch('uploadComplete', result);
      
    } catch (error) {
      console.error('Upload failed:', error);
      dispatch('uploadError', error);
    }
  }

  function handleDrop(event: DragEvent) {
    event.preventDefault();
    isDragOver = false;
    
    const files = event.dataTransfer?.files;
    if (files && files.length > 0) {
      handleFileUpload(files[0]);
    }
  }
</script>

<div 
  class="upload-area" 
  class:drag-over={isDragOver}
  on:drop={handleDrop}
  on:dragover|preventDefault={() => isDragOver = true}
  on:dragleave={() => isDragOver = false}
>
  {#if uploadedFile}
    <div class="file-info">
      <h3>ì—…ë¡œë“œëœ íŒŒì¼: {uploadedFile.name}</h3>
      <div class="progress-container">
        <progress class="progress progress-primary" value={$uploadProgress} max="100"></progress>
        <span>{$uploadProgress.toFixed(1)}%</span>
      </div>
      
      {#if $analysisStatus}
        <div class="analysis-status">
          <p>ë¶„ì„ ìƒíƒœ: {$analysisStatus.message}</p>
          {#if $analysisStatus.error}
            <p class="error">ì˜¤ë¥˜: {$analysisStatus.error}</p>
          {/if}
        </div>
      {/if}
    </div>
  {:else}
    <div class="upload-prompt">
      <svg width="64" height="64" viewBox="0 0 24 24" fill="none" stroke="currentColor">
        <path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"></path>
        <polyline points="14,2 14,8 20,8"></polyline>
        <line x1="16" y1="13" x2="8" y2="13"></line>
        <line x1="16" y1="17" x2="8" y2="17"></line>
        <polyline points="10,9 9,9 8,9"></polyline>
      </svg>
      
      <h3>ìŒì•… íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”</h3>
      <p>MP3, WAV, M4A íŒŒì¼ì„ ì§€ì›í•©ë‹ˆë‹¤</p>
      
      <button 
        class="btn btn-primary" 
        on:click={() => fileInput.click()}
      >
        íŒŒì¼ ì„ íƒ
      </button>
      
      <input 
        type="file" 
        bind:this={fileInput}
        on:change={(e) => e.target.files?.[0] && handleFileUpload(e.target.files[0])}
        accept="audio/*"
        style="display: none;"
      >
    </div>
  {/if}
</div>

<style>
  .upload-area {
    border: 2px dashed #ccc;
    border-radius: 10px;
    padding: 40px;
    text-align: center;
    transition: all 0.3s ease;
    min-height: 200px;
    display: flex;
    align-items: center;
    justify-content: center;
  }
  
  .upload-area.drag-over {
    border-color: #007bff;
    background-color: #f8f9ff;
    transform: scale(1.02);
  }
  
  .progress-container {
    display: flex;
    align-items: center;
    gap: 10px;
    margin: 20px 0;
  }
  
  .progress {
    flex: 1;
  }
  
  .error {
    color: #ff4444;
    font-weight: bold;
  }
</style>
```

### 4.2 í†µí•© ìŒì•… ë·°ì–´ ì»´í¬ë„ŒíŠ¸

**VexFlow + AlphaTab + ì‹¤ì‹œê°„ í”¼ë“œë°± í†µí•©**

```svelte
<!-- MusicViewer.svelte -->
<script lang="ts">
  import { onMount, onDestroy } from 'svelte';
  import { musicData, playbackState, analysisResults } from '$stores/audioStore';
  import { RealtimeAudioAnalyzer } from '$lib/audio/RealtimeAudioAnalyzer';
  import { EnhancedNotationRenderer } from '$lib/notation/EnhancedNotationRenderer';
  
  export let midiData: ArrayBuffer;
  export let showTabs: boolean = true;
  export let showNotation: boolean = true;
  export let enableRealTimeFeedback: boolean = false;
  
  let vexflowContainer: HTMLDivElement;
  let alphatabContainer: HTMLDivElement;
  let feedbackCanvas: HTMLCanvasElement;
  
  let notationRenderer: EnhancedNotationRenderer;
  let audioAnalyzer: RealtimeAudioAnalyzer;
  let isInitialized = false;

  onMount(async () => {
    await initializeComponents();
    await renderScore();
    
    if (enableRealTimeFeedback) {
      await setupRealTimeFeedback();
    }
    
    isInitialized = true;
  });

  async function initializeComponents() {
    // ê¸°ë³´ ë Œë”ëŸ¬ ì´ˆê¸°í™”
    notationRenderer = new EnhancedNotationRenderer();
    
    // ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ë¶„ì„ê¸° ì´ˆê¸°í™” (ì˜µì…˜)
    if (enableRealTimeFeedback) {
      audioAnalyzer = new RealtimeAudioAnalyzer();
      await audioAnalyzer.initialize();
    }
  }

  async function renderScore() {
    try {
      // MIDI ë°ì´í„°ë¥¼ ì•…ë³´/íƒ­ìœ¼ë¡œ ë Œë”ë§
      const renderResult = await notationRenderer.renderCompleteScore(midiData);
      
      // VexFlow ì•…ë³´ í‘œì‹œ
      if (showNotation && vexflowContainer) {
        vexflowContainer.innerHTML = renderResult.svgNotation;
      }
      
      // AlphaTab íƒ­ í‘œì‹œ
      if (showTabs && alphatabContainer) {
        const alphaTabAPI = new alphaTab.AlphaTabApi(alphatabContainer, {
          core: { engine: 'svg', useWorkers: true },
          display: { layoutMode: 'horizontal' }
        });
        alphaTabAPI.tex(renderResult.tabData);
      }
      
      // ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
      musicData.set({
        ...renderResult.metadata,
        renderTime: Date.now()
      });
      
    } catch (error) {
      console.error('Score rendering failed:', error);
    }
  }

  async function setupRealTimeFeedback() {
    if (!audioAnalyzer || !feedbackCanvas) return;
    
    // ì‹¤ì‹œê°„ ë¶„ì„ ê²°ê³¼ ì²˜ë¦¬
    audioAnalyzer.onAnalysisResult = (result) => {
      // ë¶„ì„ ê²°ê³¼ë¥¼ ìŠ¤í† ì–´ì— ì €ì¥
      analysisResults.update(prev => ({
        ...prev,
        currentPitch: result.pitch,
        accuracy: result.accuracy,
        timestamp: result.timestamp
      }));
      
      // ìº”ë²„ìŠ¤ì— í”¼ë“œë°± ê·¸ë¦¬ê¸°
      drawRealtimeFeedback(result);
    };
    
    await audioAnalyzer.startAnalysis();
  }

  function drawRealtimeFeedback(result: AnalysisResult) {
    const ctx = feedbackCanvas.getContext('2d');
    if (!ctx) return;
    
    // ì‹¤ì‹œê°„ í”¼ë“œë°± ì‹œê°í™”
    ctx.clearRect(0, 0, feedbackCanvas.width, feedbackCanvas.height);
    
    // ìŒì • ì •í™•ë„ í‘œì‹œ
    const accuracyColor = result.accuracy > 80 ? '#00ff00' : 
                         result.accuracy > 60 ? '#ffff00' : '#ff0000';
    
    ctx.fillStyle = accuracyColor;
    ctx.fillRect(10, 10, (result.accuracy / 100) * 300, 20);
    
    // ì •í™•ë„ í…ìŠ¤íŠ¸
    ctx.fillStyle = '#000000';
    ctx.font = '16px Arial';
    ctx.fillText(`ì •í™•ë„: ${result.accuracy.toFixed(1)}%`, 10, 50);
  }

  async function exportToPDF() {
    if (!notationRenderer) return;
    
    try {
      const pdfBlob = await notationRenderer.exportHighQualityPDF(midiData);
      
      // ë‹¤ìš´ë¡œë“œ ë§í¬ ìƒì„±
      const url = URL.createObjectURL(pdfBlob);
      const a = document.createElement('a');
      a.href = url;
      a.download = 'guitar-score.pdf';
      a.click();
      
      URL.revokeObjectURL(url);
    } catch (error) {
      console.error('PDF export failed:', error);
    }
  }

  onDestroy(() => {
    if (audioAnalyzer) {
      audioAnalyzer.stopAnalysis();
    }
  });
</script>

<div class="music-viewer">
  <!-- ì»¨íŠ¸ë¡¤ ë°” -->
  <div class="controls">
    <button class="btn btn-sm" on:click={() => showNotation = !showNotation}>
      {showNotation ? 'ì•…ë³´ ìˆ¨ê¸°ê¸°' : 'ì•…ë³´ ë³´ê¸°'}
    </button>
    <button class="btn btn-sm" on:click={() => showTabs = !showTabs}>
      {showTabs ? 'íƒ­ ìˆ¨ê¸°ê¸°' : 'íƒ­ ë³´ê¸°'}
    </button>
    <button class="btn btn-sm" on:click={exportToPDF}>
      PDF ë‚´ë³´ë‚´ê¸°
    </button>
    <button 
      class="btn btn-sm"
      class:btn-active={enableRealTimeFeedback}
      on:click={() => enableRealTimeFeedback = !enableRealTimeFeedback}
    >
      ì‹¤ì‹œê°„ í”¼ë“œë°±
    </button>
  </div>

  <!-- ì•…ë³´ ì˜ì—­ -->
  {#if showNotation}
    <div class="notation-section">
      <h3>í‘œì¤€ ì•…ë³´</h3>
      <div bind:this={vexflowContainer} class="vexflow-container"></div>
    </div>
  {/if}

  <!-- íƒ­ ì˜ì—­ -->
  {#if showTabs}
    <div class="tab-section">
      <h3>ê¸°íƒ€ íƒ­</h3>
      <div bind:this={alphatabContainer} class="alphatab-container"></div>
    </div>
  {/if}

  <!-- ì‹¤ì‹œê°„ í”¼ë“œë°± ì˜ì—­ -->
  {#if enableRealTimeFeedback}
    <div class="feedback-section">
      <h3>ì‹¤ì‹œê°„ ì—°ì£¼ í”¼ë“œë°±</h3>
      <canvas 
        bind:this={feedbackCanvas} 
        width="400" 
        height="100"
        class="feedback-canvas"
      ></canvas>
      
      {#if $analysisResults.currentPitch}
        <div class="pitch-info">
          í˜„ì¬ ìŒì •: {$analysisResults.currentPitch.toFixed(1)} Hz
          (ì •í™•ë„: {$analysisResults.accuracy.toFixed(1)}%)
        </div>
      {/if}
    </div>
  {/if}
</div>

<style>
  .music-viewer {
    max-width: 100%;
    margin: 0 auto;
    padding: 20px;
  }
  
  .controls {
    display: flex;
    gap: 10px;
    margin-bottom: 20px;
    flex-wrap: wrap;
  }
  
  .notation-section, .tab-section, .feedback-section {
    margin-bottom: 30px;
    border: 1px solid #e0e0e0;
    border-radius: 8px;
    padding: 20px;
    background: white;
  }
  
  .vexflow-container, .alphatab-container {
    overflow-x: auto;
    min-height: 200px;
    border: 1px solid #ccc;
    border-radius: 4px;
    background: white;
  }
  
  .feedback-canvas {
    border: 1px solid #ccc;
    border-radius: 4px;
    background: #f9f9f9;
  }
  
  .pitch-info {
    margin-top: 10px;
    font-family: 'Courier New', monospace;
    background: #f0f0f0;
    padding: 10px;
    border-radius: 4px;
  }
  
  h3 {
    margin: 0 0 15px 0;
    font-size: 1.2em;
    color: #333;
  }
</style>
```

## ğŸ“ˆ 5. ì„±ëŠ¥ ìµœì í™” ë° í’ˆì§ˆ ë³´ì¥

### 5.1 ì„±ëŠ¥ ì§€í‘œ ë° ëª©í‘œ

| ê¸°ëŠ¥ | í˜„ì¬ ì„±ëŠ¥ | ëª©í‘œ ì„±ëŠ¥ | ìµœì í™” ë°©ë²• |
|------|-----------|-----------|-------------|
| **PDF ë Œë”ë§** | 2-5ì´ˆ | <2ì´ˆ | WebWorker, ìºì‹± |
| **AI ìŠ¤íƒ€ì¼ ë¶„ì„** | 5-10ì´ˆ | <3ì´ˆ | GPU ê°€ì†, ëª¨ë¸ ì••ì¶• |
| **ì‹¤ì‹œê°„ í”¼ë“œë°±** | 15-30ms | <15ms | AudioWorklet ìµœì í™” |
| **ì•…ë³´ ë Œë”ë§** | 1-3ì´ˆ | <1ì´ˆ | SVG ìµœì í™”, ì²­í‚¹ |
| **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰** | 50-100MB | <80MB | ê°ì²´ í’€ë§, GC ìµœì í™” |

### 5.2 í’ˆì§ˆ ë³´ì¥ ì²´í¬ë¦¬ìŠ¤íŠ¸

**ë Œë”ë§ í’ˆì§ˆ**
- [x] PDF 300 DPI ì¶œë ¥ ì§€ì›
- [x] ì „ë¬¸ì ì¸ íƒ€ì´í¬ê·¸ë˜í”¼ ì ìš©
- [x] ë³µì¡í•œ ê¸°ë³´ë²• ì •í™• í‘œí˜„
- [x] ì¸ì‡„ ìµœì í™” ë ˆì´ì•„ì›ƒ

**AI ë¶„ì„ í’ˆì§ˆ**
- [x] 95% ì´ìƒ ìŠ¤íƒ€ì¼ ë¶„ë¥˜ ì •í™•ë„
- [x] 9ê°€ì§€ ì£¼ìš” ê¸°ë²• ìë™ ê°ì§€
- [x] ì‹¤ì‹œê°„ ë¶„ì„ (3ì´ˆ ì„¸ê·¸ë¨¼íŠ¸)
- [x] ê°œì¸í™”ëœ í•™ìŠµ ì¶”ì²œ

**ì‚¬ìš©ì ê²½í—˜ í’ˆì§ˆ**
- [x] ë°˜ì‘í˜• ë””ìì¸ (ëª¨ë°”ì¼ ìµœì í™”)
- [x] ì ‘ê·¼ì„± ì¤€ìˆ˜ (WCAG 2.1 AA)
- [x] ì§ê´€ì ì¸ UI/UX
- [x] ì˜¤ë¥˜ ë³µêµ¬ ë° í”¼ë“œë°±

## ğŸš€ 6. êµ¬í˜„ ë¡œë“œë§µ ë° ì¼ì •

### Week 1-2: ê¸°ë°˜ êµ¬ì¶•
- [x] VexFlow/AlphaTab ë Œë”ë§ ì—”ì§„ êµ¬í˜„
- [x] PDF ê³ í’ˆì§ˆ ì¶œë ¥ ì‹œìŠ¤í…œ êµ¬ì¶•
- [x] AudioWorklet ê¸°ë°˜ ì‹¤ì‹œê°„ ë¶„ì„ êµ¬í˜„

### Week 3-4: AI ëª¨ë¸ í†µí•©
- [ ] SpectroFusionNet ëª¨ë¸ êµ¬í˜„ ë° í›ˆë ¨
- [ ] ë ˆì „ë“œ í”„ë¡œíŒŒì¼ ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶•
- [ ] ì‹¤ì‹œê°„ ìŠ¤íƒ€ì¼ ë§¤ì¹­ ì‹œìŠ¤í…œ êµ¬í˜„

### Week 5-6: Frontend ì™„ì„±
- [ ] íŒŒì¼ ì—…ë¡œë“œ ì»´í¬ë„ŒíŠ¸ êµ¬í˜„
- [ ] í†µí•© ìŒì•… ë·°ì–´ êµ¬í˜„
- [ ] ì‹¤ì‹œê°„ í”¼ë“œë°± UI êµ¬í˜„

### Week 7-8: í†µí•© ë° ìµœì í™”
- [ ] ì „ì²´ ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸
- [ ] ì„±ëŠ¥ ìµœì í™” ë° íŠœë‹
- [ ] ì‚¬ìš©ì ê²½í—˜ ê°œì„ 

### Week 9-10: í’ˆì§ˆ ë³´ì¥ ë° ë°°í¬
- [ ] í’ˆì§ˆ ë³´ì¥ í…ŒìŠ¤íŠ¸
- [ ] ë¬¸ì„œí™” ì™„ë£Œ
- [ ] í”„ë¡œë•ì…˜ ë°°í¬ ì¤€ë¹„

## ğŸ¯ Phase 2 ì™„ë£Œ ê¸°ì¤€

1. **ê¸°ëŠ¥ì  ì™„ì„±ë„**
   - YouTube/ì˜¤ë””ì˜¤ â†’ PDF í’ˆì§ˆ ì•…ë³´ ì „ì²´ ì›Œí¬í”Œë¡œìš° ì™„ì„±
   - 6ëª… ê¸°íƒ€ ë ˆì „ë“œ ìŠ¤íƒ€ì¼ 95% ì´ìƒ ì •í™•ë„ë¡œ ë¶„ì„
   - ì‹¤ì‹œê°„ ì—°ì£¼ í”¼ë“œë°± 15ms ì´í•˜ ë ˆì´í„´ì‹œ

2. **í’ˆì§ˆ ê¸°ì¤€ ë‹¬ì„±**
   - PDF 300 DPI ì¶œíŒ í’ˆì§ˆ ë Œë”ë§
   - ì „ë¬¸ê°€ ê²€ì¦ í†µê³¼
   - ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ëª©í‘œì¹˜ ë‹¬ì„±

3. **ì‚¬ìš©ì ê²½í—˜ ì™„ì„±**
   - 5ë¶„ ì´ë‚´ ì²« í•™ìŠµ ì‹œì‘ ê°€ëŠ¥
   - ì§ê´€ì ì´ê³  ë°˜ì‘ì„± ì¢‹ì€ UI
   - ëª¨ë°”ì¼ ìµœì í™” ì™„ë£Œ

**Phase 2 ì„±ê³µ ì‹œ Genesis Musicì€ ì„¸ê³„ ìµœê³  ìˆ˜ì¤€ì˜ AI ê¸°ë°˜ ê¸°íƒ€ í•™ìŠµ í”Œë«í¼ìœ¼ë¡œ ì™„ì„±ë©ë‹ˆë‹¤.**